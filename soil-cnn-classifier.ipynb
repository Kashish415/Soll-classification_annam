{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports \nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setting random seeds for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False  # For true reproducibility\n\n# Device Configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Running on: {device}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:03.574105Z","iopub.execute_input":"2025-05-23T07:03:03.574557Z","iopub.status.idle":"2025-05-23T07:03:03.580979Z","shell.execute_reply.started":"2025-05-23T07:03:03.574535Z","shell.execute_reply":"2025-05-23T07:03:03.580408Z"}},"outputs":[{"name":"stdout","text":"Running on: cuda\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Loading CSV files\nBASE = '/kaggle/input/soil-classification/soil_classification-2025'\ndf_train = pd.read_csv(os.path.join(BASE, 'train_labels.csv'))\ndf_test  = pd.read_csv(os.path.join(BASE, 'test_ids.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:04.099459Z","iopub.execute_input":"2025-05-23T07:03:04.099680Z","iopub.status.idle":"2025-05-23T07:03:04.113597Z","shell.execute_reply.started":"2025-05-23T07:03:04.099664Z","shell.execute_reply":"2025-05-23T07:03:04.112902Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Standardize Column Names\n# Training CSV has columns ['image_id', 'soil_type']\n# Test CSV has ['image_id']\ndf_train = df_train.rename(columns={'image_id': 'id', 'soil_type': 'label'})\ndf_test  = df_test.rename(columns={'image_id': 'id'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:04.610161Z","iopub.execute_input":"2025-05-23T07:03:04.610675Z","iopub.status.idle":"2025-05-23T07:03:04.615329Z","shell.execute_reply.started":"2025-05-23T07:03:04.610657Z","shell.execute_reply":"2025-05-23T07:03:04.614665Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Encoding string labels to integers\nclasses = sorted(df_train['label'].unique())\ncls2idx = {c: i for i, c in enumerate(classes)}\nidx2cls = {i: c for c, i in cls2idx.items()}\n\n# Map label column to integer index\ndf_train['label_idx'] = df_train['label'].map(cls2idx)\n\nprint(\"Label mapping:\", cls2idx)\nprint(df_train[['id', 'label', 'label_idx']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:05.055167Z","iopub.execute_input":"2025-05-23T07:03:05.055709Z","iopub.status.idle":"2025-05-23T07:03:05.065991Z","shell.execute_reply.started":"2025-05-23T07:03:05.055691Z","shell.execute_reply":"2025-05-23T07:03:05.065260Z"}},"outputs":[{"name":"stdout","text":"Label mapping: {'Alluvial soil': 0, 'Black Soil': 1, 'Clay soil': 2, 'Red soil': 3}\n                 id          label  label_idx\n0  img_ed005410.jpg  Alluvial soil          0\n1  img_0c5ecd2a.jpg  Alluvial soil          0\n2  img_ed713bb5.jpg  Alluvial soil          0\n3  img_12c58874.jpg  Alluvial soil          0\n4  img_eff357af.jpg  Alluvial soil          0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# PyTorch Dataset\nclass SoilDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_test=False):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id'])\n\n        # Load image safely\n        try:\n            img = Image.open(img_path).convert('RGB')\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load image: {img_path} | Error: {e}\")\n\n        # Apply transforms (if any)\n        if self.transform:\n            img = self.transform(img)\n\n        # Return differently for test/train\n        if self.is_test:\n            return img, row['id']\n        else:\n            return img, row['label_idx']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:05.331232Z","iopub.execute_input":"2025-05-23T07:03:05.331698Z","iopub.status.idle":"2025-05-23T07:03:05.337619Z","shell.execute_reply.started":"2025-05-23T07:03:05.331679Z","shell.execute_reply":"2025-05-23T07:03:05.336856Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Image Transforms\nIMG_SIZE = 224\ntransform_train = T.Compose([\n    T.Resize((IMG_SIZE, IMG_SIZE)),\n    T.RandomHorizontalFlip(),\n    T.RandomRotation(15),\n    T.ToTensor(),\n])\n\ntransform_val = T.Compose([\n    T.Resize((IMG_SIZE, IMG_SIZE)),\n    T.ToTensor(),\n])\n\n# Stratified Train/Validation Split\ndf_tr, df_val = train_test_split(\n    df_train,\n    test_size=0.2,\n    stratify=df_train['label_idx'],\n    random_state=42\n)\n\n# Datasets\ntrain_ds = SoilDataset(df_tr, os.path.join(BASE, 'train'), transform_train)\nval_ds   = SoilDataset(df_val, os.path.join(BASE, 'train'), transform_val)\ntest_ds  = SoilDataset(df_test, os.path.join(BASE, 'test'), transform_val, is_test=True)\n\n# Dataloaders\nBATCH_SIZE = 32\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\ntest_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(f\"Train: {len(train_loader)} batches\")\nprint(f\"Val:   {len(val_loader)} batches\")\nprint(f\"Test:  {len(test_loader)} batches\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:09.005016Z","iopub.execute_input":"2025-05-23T07:03:09.005493Z","iopub.status.idle":"2025-05-23T07:03:09.017703Z","shell.execute_reply.started":"2025-05-23T07:03:09.005470Z","shell.execute_reply":"2025-05-23T07:03:09.016875Z"}},"outputs":[{"name":"stdout","text":"Train: 31 batches\nVal:   8 batches\nTest:  11 batches\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import torchvision.models as models\n\n# Partially fine-tuned ResNet18 Classifier with Dropout\nclass ResNet18Classifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.base_model = models.resnet18(weights='IMAGENET1K_V1')\n\n        # Freeze all layers first\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n\n        # Unfreeze layer4\n        for param in self.base_model.layer4.parameters():\n            param.requires_grad = True\n\n        # Add Dropout before final FC layer\n        in_features = self.base_model.fc.in_features\n        self.base_model.fc = nn.Sequential(\n            nn.Dropout(p=0.4),\n            nn.Linear(in_features, num_classes)\n        )\n\n    def forward(self, x):\n        return self.base_model(x)\n\n# Instantiate the model\nmodel = ResNet18Classifier(len(classes)).to(device)\n\n# Set up parameter groups for different learning rates\nlayer4_params = list(model.base_model.layer4.parameters())\nfc_params = list(model.base_model.fc.parameters())\n\noptimizer = torch.optim.Adam([\n    {'params': layer4_params, 'lr': 1e-4},\n    {'params': fc_params, 'lr': 1e-3}\n])\n\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:11.360847Z","iopub.execute_input":"2025-05-23T07:03:11.361151Z","iopub.status.idle":"2025-05-23T07:03:11.606464Z","shell.execute_reply.started":"2025-05-23T07:03:11.361129Z","shell.execute_reply":"2025-05-23T07:03:11.605801Z"}},"outputs":[{"name":"stdout","text":"ResNet18Classifier(\n  (base_model): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Sequential(\n      (0): Dropout(p=0.4, inplace=False)\n      (1): Linear(in_features=512, out_features=4, bias=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# Compute class weights\nclass_counts = df_train['label_idx'].value_counts().sort_index().values\nweights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\nweights = weights / weights.sum()\ncriterion = nn.CrossEntropyLoss(weight=weights.to(device))\n\n# Scheduler for new optimizer (already defined earlier)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n\nEPOCHS = 30\nbest_f1 = 0\n\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    total_loss = 0\n    for imgs, labels in train_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    avg_loss = total_loss / len(train_loader)\n\n    # Validation\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs = imgs.to(device)\n            outputs = model(imgs)\n            _, preds = outputs.max(1)\n            all_preds += preds.cpu().tolist()\n            all_labels += labels.tolist()\n\n    val_f1 = f1_score(all_labels, all_preds, average='macro')\n    print(f\"Epoch {epoch}/{EPOCHS} - Loss: {avg_loss:.4f}, Val F1: {val_f1:.4f}\")\n    scheduler.step()\n\n    # Save best model\n    if val_f1 > best_f1:\n        best_f1 = val_f1\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f\"New best model saved with F1: {best_f1:.4f}\")\n\n# Save final model\ntorch.save(model.state_dict(), 'last_model.pth')\nprint(\"Saved last_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:03:15.594799Z","iopub.execute_input":"2025-05-23T07:03:15.595124Z","iopub.status.idle":"2025-05-23T07:06:38.185825Z","shell.execute_reply.started":"2025-05-23T07:03:15.595102Z","shell.execute_reply":"2025-05-23T07:06:38.184892Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30 - Loss: 0.5612, Val F1: 0.9270\nNew best model saved with F1: 0.9270\nEpoch 2/30 - Loss: 0.1751, Val F1: 0.9577\nNew best model saved with F1: 0.9577\nEpoch 3/30 - Loss: 0.1149, Val F1: 0.9542\nEpoch 4/30 - Loss: 0.0718, Val F1: 0.9622\nNew best model saved with F1: 0.9622\nEpoch 5/30 - Loss: 0.0702, Val F1: 0.9592\nEpoch 6/30 - Loss: 0.0743, Val F1: 0.9794\nNew best model saved with F1: 0.9794\nEpoch 7/30 - Loss: 0.0415, Val F1: 0.9671\nEpoch 8/30 - Loss: 0.0341, Val F1: 0.9714\nEpoch 9/30 - Loss: 0.0459, Val F1: 0.9753\nEpoch 10/30 - Loss: 0.0357, Val F1: 0.9755\nEpoch 11/30 - Loss: 0.0268, Val F1: 0.9755\nEpoch 12/30 - Loss: 0.0360, Val F1: 0.9755\nEpoch 13/30 - Loss: 0.0254, Val F1: 0.9755\nEpoch 14/30 - Loss: 0.0313, Val F1: 0.9755\nEpoch 15/30 - Loss: 0.0278, Val F1: 0.9753\nEpoch 16/30 - Loss: 0.0228, Val F1: 0.9753\nEpoch 17/30 - Loss: 0.0180, Val F1: 0.9755\nEpoch 18/30 - Loss: 0.0210, Val F1: 0.9755\nEpoch 19/30 - Loss: 0.0285, Val F1: 0.9755\nEpoch 20/30 - Loss: 0.0272, Val F1: 0.9796\nNew best model saved with F1: 0.9796\nEpoch 21/30 - Loss: 0.0278, Val F1: 0.9755\nEpoch 22/30 - Loss: 0.0232, Val F1: 0.9755\nEpoch 23/30 - Loss: 0.0288, Val F1: 0.9755\nEpoch 24/30 - Loss: 0.0240, Val F1: 0.9755\nEpoch 25/30 - Loss: 0.0227, Val F1: 0.9755\nEpoch 26/30 - Loss: 0.0241, Val F1: 0.9755\nEpoch 27/30 - Loss: 0.0184, Val F1: 0.9755\nEpoch 28/30 - Loss: 0.0275, Val F1: 0.9755\nEpoch 29/30 - Loss: 0.0242, Val F1: 0.9755\nEpoch 30/30 - Loss: 0.0284, Val F1: 0.9755\nSaved last_model.pth\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Load best model before inference\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\n\nids, preds = [], []\nwith torch.no_grad():\n    for imgs, img_ids in test_loader:\n        imgs = imgs.to(device)\n        outputs = model(imgs)\n        _, p = outputs.max(1)\n        ids += img_ids\n        preds += p.cpu().tolist()\n\n# Map back to class names\nlabels = [idx2cls[i] for i in preds]\nsubmission = pd.DataFrame({'image_id': ids, 'soil_type': labels})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"submission.csv created using best_model.pth!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:18:54.380767Z","iopub.execute_input":"2025-05-23T07:18:54.381580Z","iopub.status.idle":"2025-05-23T07:18:56.012528Z","shell.execute_reply.started":"2025-05-23T07:18:54.381551Z","shell.execute_reply":"2025-05-23T07:18:56.011776Z"}},"outputs":[{"name":"stdout","text":"submission.csv created using best_model.pth!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Load best model before evaluation\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\n\nall_trues, all_preds = [], []\n\nwith torch.no_grad():\n    for imgs, labels in val_loader:  \n        imgs = imgs.to(device)\n        outputs = model(imgs)\n        _, preds = outputs.max(1)\n        all_preds += preds.cpu().tolist()\n        all_trues += labels.tolist()\n\n# Compute per-class F1 and take minimum\nper_class_f1 = f1_score(all_trues, all_preds, average=None)\nmin_f1 = per_class_f1.min()\n\nprint(f\"Per-class F1 scores: {per_class_f1}\")\nprint(f\"Final metric (minimum F1): {min_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:18:56.013848Z","iopub.execute_input":"2025-05-23T07:18:56.014084Z","iopub.status.idle":"2025-05-23T07:18:57.518696Z","shell.execute_reply.started":"2025-05-23T07:18:56.014061Z","shell.execute_reply":"2025-05-23T07:18:57.517852Z"}},"outputs":[{"name":"stdout","text":"Per-class F1 scores: [0.97584541 0.9787234  0.96385542 1.        ]\nFinal metric (minimum F1): 0.9639\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}